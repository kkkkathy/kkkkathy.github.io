---
title: 极大似然估计的理解
date: 2018-12-10 15:52:20
tag: [决策树,逻辑回归]
categories: 算法原理
---

先举一个例子方便理解：

- 一个袋子中总共有黑白两种颜色100个球，其中一种颜色90个，随机取出一个球，发现是黑球。

那么我们大概率猜测90个的是黑色球，因为黑色抽中的概率最大。



### 极大似然估计（maximum likelihood estimation, MLE）

- 通俗的理解为：有n个实验结果，$A_i$到$A_n$，如果$A_j$发生了，则意味着$A_j$发生的概率最大。


- 抽象一点，如果事件发生是关于$\theta$参数的，对于样本$x_1,...,x_k$，$\hat{\theta}(x_1,...,x_k)$就是$\theta$的估计值，当$\theta=\hat{\theta}(x_1,...,x_k)$时，样本发生概率最大

#### 当总体X为离散型

- $p(x;\theta)$表示估计参数为$\theta$时，发生$x$的概率

- 当样本值为：$x_1,...,x_n$时：
  $$
  L(\theta)=L(x_1,x_2,...,x_n;\theta)=\prod_{i=1}^np(x_i;\theta)
  $$
  其中$L(\theta)$是样本的似然函数，我们的目标就是找到一个$\hat{\theta}$使得$L(\theta)$取值最大，此时$\hat{\theta}$叫做参数$\theta$的极大似然估计值。

#### 当总体X为连续型

- 概率密度函数$f(x;\theta)$代替p。
- 解法为：
  - 构造似然函数$L(\theta)$
  - 取对数$lnL(\theta)$
  - 求导计算极值
  - 解方程，得到$\theta$
- 使用log的好处在于：
  - 对数函数属于单调递增函数，不会改变极值点的位置
  - 对数计算法则使得求导十分方便（比如$lna^b=blna$，以及乘法变加法等）



### 举例——高斯分布的MLE

高斯函数：
$$
p(x|\mu,\sigma)=\frac{1}{\sqrt{2\pi}\sigma}exp\{-\frac{(x-\mu)^2}{2\sigma^2}\}
$$
可以通过MLE来计算：
$$
l(\mu,\sigma)=\sum_{i=1}^Nlog(p(x_i|\mu,\sigma))
$$
$$
=\sum_{i=0}^N\{log(-\sqrt{2\pi}\sigma)-\frac{(x-\mu)^2}{2\sigma^2}\}
$$

$$
=-\frac{1}{2\sigma^2}\sum_{i=1}^N(x-\mu)^2-Nlog\sigma-\frac{N}{2}log2\pi
$$

分别对$\mu$和$\sigma$求偏导：
$$
\frac{\partial l}{\partial \mu}=\sum_{i=0}^N(x_i-\mu)=0
$$

$$
\frac{\partial l}{\partial \sigma}=\frac{1}{\sigma^3}\sum_{i=0}^N(x_i-\mu)^2-\frac{N}{\sigma}=0
$$

从而可求得$\mu$和$\sigma$的值。







